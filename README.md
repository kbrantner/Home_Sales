# Home_Sales

 
#Description

In this project I looked at home sales data from 2019-2022. In order to analyze the data I used SparkSQL which allowed me to create temporary views, both cache and uncache tables, and partition the data. Throughout the code, the specific questions that are being answered through analysis are listed at the top of the relevant section of code. 

#Installation

For this project the following imports are required:
Please note that the spark version was updated to ‘spark-3.4.0’ since ‘spark-3.3.1’ is no longer supported. 
import os
spark_version = 'spark-3.4.0'
os.environ['SPARK_VERSION']=spark_version

To install Spark and Java:
!apt-get update
!apt-get install openjdk-11-jdk-headless -qq > /dev/null
!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz
!tar xf $SPARK_VERSION-bin-hadoop3.tgz
!pip install -q findspark

To set environment variables:
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-11-openjdk-amd64"
os.environ["SPARK_HOME"] = f"/content/{spark_version}-bin-hadoop3"


import findspark
findspark.init()

from pyspark.sql.functions import year

from pyspark.sql import SparkSession
import time

from pyspark import SparkFiles

#Support

To look up the most recent version of spark, please visit https://downloads.apache.org/spark/. If additional help is needed, I recommend searching Stack Overflow for assistance. 

#Authors and acknowledgment

This project was completed by Kelsey Brantner. Bethany Lindberg helped me understand the necessary steps for completing the partition by function, and which steps I had originally coded were unnecessary. 

#License

According to the file’s source site, “Data for this dataset was generated by edX Boot Camps LLC, and is intended for educational purposes only.”

#Project Status

At this time, I consider the code to be complete. 
